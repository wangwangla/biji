## BP神经网络

- 多层前反馈网络

  - 信号前向传递，误差反向传播
  - 信号从输入层，在隐藏层进行传播，直到输出
  - 每一个神经元只会影响下一层神经网络
  - 输出层得不到想要的结果就会反向传播，根据误差，调整阈值
  - 从而使得其不断的逼近网络

- BP组成

  - 输入
  - 输出预测值
  - 输入n，输出m，那么就体现出n向m的映射

- BP操作

  BP预测前需要进行训练资源，通过训练使其可以进行联想和预测能力

  - 网络初始化：根据输出确定输入和输出节点n，隐含层节点l，输出层节点m，初始化输入层，隐含层，输出层直接的练级权值  初始化隐含层阈值，输出层阈值，给定学习速率和神经元的激励函数。
  - 隐含层输出计算 根据输入X，输入层和隐含层间连接权值以及隐含层阈值，计算隐含层的输出H
  - 输出层输出计算
  - 误差计算
  - 权值更新
  - 阈值更新
  - 检测是否接受，未结束，那么从2开始

- 案例：

  语音特性信号识别：

  - 语言转化为电
  - 提取语音特性信号
  - 改成语音模式
  - 和语音模型同参考进行比较

  分析

  - 输入24类语音
  - 分为4类
  - 隐含层节点：25

- 实现

  - 归一化函数

    归一化是神经网络处理的一种处理方法，将数据转化为[0,1],取消数量级的差异，避免输入输出数据的级别差太大，造成误差过大。

    常用方法：

    - 最大值最小值方法

      ```
      [inputn,inputps] = mapminmax(input_train);
      [outputn,outputps] = mapminmax(output_train);
      ```

      

    - 平均数方差法

  - 数据进行归一化处理

  - 对网络进行初始化

  - BP神经网络进行训练

  - BP神经网络分类

- 其他

  - 隐含节点数

    - 太多：过拟合

    - 太少：达不到要求

      ​	l<n-1

       	l<开根号（m+n）+a

      ​	l=log3(n)

      n：输入节点

      l:隐含层节点数

      m:输出层节点数

      a:0~10的常数

    - 一般情况下，隐藏节点数增加就是越来误差越小，但是如果过大，又会增加

- 权值和阈值

  - 采样修正法作为权值和阈值的学习算法，误差的负梯度进行修正权值和阈值，不考虑之前的经验，会使收敛慢，可以使用附加动量权值学习方法
  - 

- 